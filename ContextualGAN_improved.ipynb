{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate, BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Lambda\n",
    "\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.losses import mean_absolute_error\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "import natsort\n",
    "import scipy\n",
    "import sys\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_filename(path):\n",
    "    dirFiles = os.listdir(path)\n",
    "    for i, file in enumerate(dirFiles):\n",
    "        dirFiles[i] = path + file\n",
    "    return natsort.natsorted(dirFiles ,reverse=False)\n",
    "\n",
    "# load all images in a directory into memory\n",
    "def load_images(list_path, size=(256, 256)):\n",
    "    img_list = list()\n",
    "    # enumerate filenames in directory, assume all are images\n",
    "    for filename in list_path:\n",
    "        # load and resize the image\n",
    "        pixels = load_img(filename, target_size=size)\n",
    "        # convert to numpy array\n",
    "        pixels = img_to_array(pixels)\n",
    "        pixels = (pixels - 127.5) / 127.5\n",
    "        img_list.append(pixels)\n",
    "    return np.asarray(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a batch of random samples, returns images and target\n",
    "def generate_real_samples(dataset, n_samples, patch_shape):\n",
    "    # unpack dataset\n",
    "    trainA, trainB = dataset\n",
    "\n",
    "    # choose random instances\n",
    "    ix = np.random.randint(0, trainA.shape[0], n_samples)\n",
    "    \n",
    "    # retrieve selected images\n",
    "    X1, X2 = trainA[ix], trainB[ix]\n",
    "    \n",
    "    # generate 'real' class labels (1)\n",
    "    y = np.ones((n_samples, patch_shape, patch_shape, 1))\n",
    "    \n",
    "    return [X1, X2], y\n",
    "\n",
    "# generate a batch of images, returns images and targets\n",
    "def generate_fake_samples(g_model, samples, patch_shape):\n",
    "    # generate fake instance\n",
    "    X = g_model.predict(samples)\n",
    "    \n",
    "    # create 'fake' class labels (0)\n",
    "    y = np.zeros((len(X), patch_shape, patch_shape, 1))\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a batch of images, returns images and targets\n",
    "def generate_fake_samples(g_model, samples, patch_shape):\n",
    "    # generate fake instance\n",
    "    X = g_model.predict(samples)\n",
    "    \n",
    "    # create 'fake' class labels (0)\n",
    "    y = np.zeros((len(X), patch_shape, patch_shape, 1))\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# generate samples and save as a plot and save the model\n",
    "def summarize_performance(step, g_model, d_model, dataset, target_dir='', n_samples=3):\n",
    "    if target_dir and not os.path.exists(target_dir):\n",
    "        os.mkdir(target_dir)\n",
    "    # select a sample of input images\n",
    "    [X_realA, X_realB], _ = generate_real_samples(dataset, n_samples, 1)\n",
    "    # generate a batch of fake samples\n",
    "    X_fakeB, _ = generate_fake_samples(g_model, X_realA, 1)\n",
    "    # scale all pixels from [-1,1] to [0,1]\n",
    "    X_realA = (X_realA + 1) / 2.0\n",
    "    X_realB = (X_realB + 1) / 2.0\n",
    "    X_fakeB = (X_fakeB + 1) / 2.0\n",
    "    # plot real source images\n",
    "    for i in range(n_samples):\n",
    "        plt.subplot(3, n_samples, 1 + i)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(X_realA[i])\n",
    "    # plot generated target image\n",
    "    for i in range(n_samples):\n",
    "        plt.subplot(3, n_samples, 1 + n_samples + i)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(X_fakeB[i])\n",
    "    # plot real target image\n",
    "    for i in range(n_samples):\n",
    "        plt.subplot(3, n_samples, 1 + n_samples*2 + i)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(X_realB[i])\n",
    "    # save plot to file\n",
    "    filename1 = 'plot_%06d.png' % (step+1)\n",
    "    plt.savefig(target_dir + filename1)\n",
    "    plt.close()\n",
    "    # save the generator model\n",
    "    g_model.save(target_dir + 'g_model.h5')\n",
    "    \n",
    "    # save the discriminator model\n",
    "    d_model.save(target_dir + 'd_model.h5')\n",
    "    \n",
    "    print('>Saved: %s and %s' % (filename1, 'g_model & d_model'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(img_shape):\n",
    "    def conv2d(layer_in, n_filter, norm=True):\n",
    "        d = Conv2D(n_filter, kernel_size=4, strides=2, padding='same')(layer_in)\n",
    "        d = LeakyReLU(0.2)(d)\n",
    "        if norm:\n",
    "            d = InstanceNormalization()(d)\n",
    "        return d\n",
    "    \n",
    "    \n",
    "    def deconv2d(layer_in, skip_in, n_filter, dropout=0.5):\n",
    "        # Using Conv2D to increase depth to the square of the upsampling size of the target\n",
    "        d = Conv2D(n_filter * 4, kernel_size=4, strides=1, padding='same', activation='relu')(layer_in)\n",
    "        if dropout:\n",
    "            d = Dropout(dropout)(d)\n",
    "        d = InstanceNormalization()(d)\n",
    "        # Using PixelShuffle for upsampling\n",
    "        d = Concatenate()([d, skip_in])\n",
    "        return d\n",
    "    \n",
    "    # Input Layer\n",
    "    in_img = Input(shape=img_shape)\n",
    "    \n",
    "    # Downsampling\n",
    "    d1 = conv2d(in_img, 64, norm=False)\n",
    "    d2 = conv2d(d1, 128)\n",
    "    d3 = conv2d(d2, 256)\n",
    "    d4 = conv2d(d3, 512)\n",
    "    d5 = conv2d(d4, 512)\n",
    "    d6 = conv2d(d5, 512)\n",
    "    d7 = conv2d(d6, 512)\n",
    "    \n",
    "    # Upsampling\n",
    "    u1 = deconv2d(d7, d6, 512)\n",
    "    u2 = deconv2d(u1, d5, 512)\n",
    "    u3 = deconv2d(u2, d4, 512)\n",
    "    u4 = deconv2d(u3, d3, 256, dropout=0)\n",
    "    u5 = deconv2d(u4, d2, 128, dropout=0)\n",
    "    u6 = deconv2d(u5, d1, 64, dropout=0)\n",
    "    u6 = Conv2D(64 * 4, kernel_size=4, strides=1, padding='same', activation='relu')(u6)\n",
    "    u7 = Lambda(lambda x: tf.nn.depth_to_space(x, 2))(u6)\n",
    "    out_img = Conv2D(3, kernel_size=4, strides=1, padding='same', activation='tanh')(u7)\n",
    "    \n",
    "    return Model(in_img, out_img, name='generator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(img_shape):\n",
    "    def d_layer(layer_in, n_filter, norm=True):\n",
    "        d = Conv2D(n_filter, kernel_size=4, strides=2, padding='same')(layer_in)\n",
    "        d = LeakyReLU(0.2)(d)\n",
    "        if norm:\n",
    "            d = InstanceNormalization()(d)\n",
    "        return d\n",
    "    \n",
    "    in_src_img = Input(shape=img_shape)\n",
    "    in_target_img = Input(shape=img_shape)\n",
    "    \n",
    "    merged = Concatenate()([in_src_img, in_target_img])\n",
    "    \n",
    "    d1 = d_layer(merged, 64, norm=False)\n",
    "    d2 = d_layer(d1, 128)\n",
    "    d3 = d_layer(d1, 256)\n",
    "    d4 = d_layer(d1, 512)\n",
    "\n",
    "    out = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n",
    "    \n",
    "    return Model([in_src_img, in_target_img], out, name='discriminator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GAN(g_model, d_model, img_shape):\n",
    "    d_model.trainable = False\n",
    "    in_img = Input(shape=img_shape)\n",
    "    gen_out = g_model(in_img)\n",
    "    dis_out = d_model([in_img, gen_out])\n",
    "    model = Model(in_img, [dis_out, gen_out], name='GAN')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train GAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(d_model, g_model, gan_model, data, target_dir, n_epochs=100, n_batch=16):\n",
    "    # determine the output square shape of the discriminator\n",
    "    n_patch = d_model.output_shape[1]\n",
    "    \n",
    "    blue_photo = data[0]\n",
    "    blue_sketch = data[1]\n",
    "    \n",
    "    for i in range(n_epochs):\n",
    "        print(' ========== Epoch', i+1, '========== ')\n",
    "        \n",
    "        blue_photo, blue_sketch = shuffle(blue_photo, blue_sketch)\n",
    "\n",
    "        for j in range(int(len(blue_photo)/n_batch)):\n",
    "            \n",
    "            start = int(j*n_batch)\n",
    "            end = int(min(len(blue_photo), (j*n_batch)+n_batch))\n",
    "            \n",
    "            dataset = [load_images(blue_photo[start:end]), load_images(blue_sketch[start:end])]\n",
    "\n",
    "            # select a batch of real samples\n",
    "            [X_realA, X_realB], y_real = generate_real_samples(dataset, n_batch, n_patch)\n",
    "\n",
    "            # generate a batch of fake samples\n",
    "            X_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n",
    "            \n",
    "            # update discriminator for real samples\n",
    "            d_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\n",
    "            \n",
    "            # update discriminator for generated samples\n",
    "            d_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n",
    "            \n",
    "            d_loss = 0.5 * np.add(d_loss1, d_loss2)\n",
    "            \n",
    "            # update the generator\n",
    "            g_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])\n",
    "            \n",
    "            # summarize performance\n",
    "            print('Batch : %d, D Loss : %.3f | G Loss : %.3f' % (j+1, d_loss, g_loss))\n",
    "        \n",
    "        summarize_performance(i, g_model, d_model, dataset, target_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_loss(y_true, y_pred):\n",
    "    return K.mean(K.abs(y_true - y_pred))\n",
    "\n",
    "def contextual_loss (y_true, y_pred):\n",
    "    a = tf.image.rgb_to_grayscale(tf.slice(\n",
    "                                y_pred, \n",
    "                                [0,0,0,0], \n",
    "                                [16, 256, 256, 3]))\n",
    "    \n",
    "    b = tf.image.rgb_to_grayscale(tf.slice(\n",
    "                                y_true, \n",
    "                                [0,0,0,0], \n",
    "                                [16, 256, 256, 3]))\n",
    "    \n",
    "    y_pred = tf.divide(tf.add(tf.reshape(a, [tf.shape(a)[0], -1]), 1), 2)\n",
    "    y_true = tf.divide(tf.add(tf.reshape(b, [tf.shape(b)[0], -1]), 1), 2)\n",
    "    \n",
    "    p_shape = tf.shape(y_true)\n",
    "    q_shape = tf.shape(y_pred)\n",
    "    \n",
    "    # normalize sum to 1\n",
    "    p_ = tf.divide(y_true, tf.tile(tf.expand_dims(tf.reduce_sum(y_true, axis=1), 1), [1,p_shape[1]]))\n",
    "    q_ = tf.divide(y_pred, tf.tile(tf.expand_dims(tf.reduce_sum(y_pred, axis=1), 1), [1,p_shape[1]]))\n",
    "    \n",
    "    return tf.reduce_sum(tf.multiply(p_, tf.log(tf.divide(p_, q_))), axis=1)\n",
    "\n",
    "def total_loss (y_true, y_pred):\n",
    "\n",
    "    px_loss = pixel_loss(y_true, y_pred)\n",
    "\n",
    "    ctx_loss = contextual_loss(y_true, y_pred)\n",
    "    \n",
    "    return (0.2 * px_loss) + (0.8 * ctx_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # dataset path\n",
    "    b_photo_path = 'Dataset/Augmented photo/'\n",
    "    b_sketch_path = 'Dataset/Augmented sketch/'\n",
    "\n",
    "    blue_photo = load_filename(b_photo_path)\n",
    "    blue_sketch = load_filename(b_sketch_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define GAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (256, 256, 3)\n",
    "d_model = discriminator(img_shape)\n",
    "g_model = generator(img_shape)\n",
    "gan_model = GAN(g_model, d_model, img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=2e-4, beta_1=0.5)\n",
    "d_model.compile(loss=wasserstein_loss, optimizer=opt)\n",
    "gan_model.compile(loss=[wasserstein_loss, gradient_penalty_loss], optimizer=opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(d_model, g_model, gan_model, [blue_sketch, blue_photo], 'Models/Pixel[02]_Context[08]_ps_conv2d_lambda/', n_epochs = 20, n_batch=16)\n",
    "print('Training Done!')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
